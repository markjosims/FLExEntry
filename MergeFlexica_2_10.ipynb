{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from GenerateLexDir import literal_eval_col\n",
    "from datetime import datetime\n",
    "from FindBib import read_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dfs\n",
    "flexicon = pd.read_csv('flexiconPART.csv', index_col='entry_id', keep_default_na=False)\n",
    "new_data = pd.read_csv('Flexport_2_1/Flexicon_NewDataPART.csv', index_col='entry_id', keep_default_na=False)\n",
    "matches  = pd.read_csv('new_entries_matchesPART.csv', index_col='entry_id', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate cols as native python types\n",
    "literal_eval_col(flexicon, 'these_vars')\n",
    "literal_eval_col(flexicon, 'variant_of')\n",
    "literal_eval_col(flexicon, 'other_sources')\n",
    "\n",
    "literal_eval_col(new_data, 'these_vars')\n",
    "literal_eval_col(new_data, 'variant_of')\n",
    "\n",
    "literal_eval_col(matches, 'matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_these = [x in ('delete from clean', 'delete new & clean') for x in matches['status']]\n",
    "delete_these = matches[delete_these]\n",
    "delete_these.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only include entries edited since recent field trip\n",
    "cutoff = datetime(2019, 11, 3)\n",
    "new = [read_date(t) > cutoff for t in new_data['date_modified']]\n",
    "new_data = new_data[new]\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove idcs of delete_these from flexicon\n",
    "# but first, transfer any data in other_sources and these_vars to new_data\n",
    "\n",
    "new_data.loc[:,'other_sources'] = [{} for row in new_data.iterrows()]\n",
    "\n",
    "new_data.loc[:, 'these_vars'] = [x if x else {} for x in new_data['these_vars']]\n",
    "        \n",
    "for index, row in matches.iterrows():\n",
    "    match_idcs = row['matches'].keys()\n",
    "    fl_other_sources = [flexicon.at[i, 'other_sources'] for i in match_idcs]\n",
    "    for x in fl_other_sources:\n",
    "        if x:\n",
    "            new_data.at[i, 'other_sources'].update(x)\n",
    "    fl_these_vars =    [flexicon.at[i, 'these_vars']    for i in match_idcs]\n",
    "    for x in fl_these_vars:\n",
    "        if x:\n",
    "            new_data.at[i, 'these_vars'].update(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1339, 10)\n",
      "(1337, 10)\n"
     ]
    }
   ],
   "source": [
    "# now we can drop all entries that have been marked for deletion from flexicon\n",
    "print(flexicon.shape)\n",
    "flexicon = flexicon.drop(match_idcs)\n",
    "print(flexicon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can drop all enries marked for deletion from new_data\n",
    "delete_these = [x in ('delete new', 'delete clean & new') for x in matches['status']]\n",
    "delete_these = matches[delete_these]\n",
    "delete_these.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop indices\n",
    "for i in delete_these.index:\n",
    "    new_data = new_data.drop(i)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1609, 11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge df's\n",
    "merged_df = pd.concat([flexicon, new_data])\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('FlexiconMERGE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
