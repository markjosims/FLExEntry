{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38132bit17ba008915ed4c9bb61ebeaf97cf1bfc",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entry_id</th>\n      <th>bibliography</th>\n      <th>date</th>\n      <th>date_modified</th>\n      <th>headword</th>\n      <th>morph_type</th>\n      <th>note</th>\n      <th>other_sources</th>\n      <th>pronunciation</th>\n      <th>sense</th>\n      <th>these_vars</th>\n      <th>variant_of</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wao taah_002ca005-1366-4a7b-aff1-ac10db10b768</td>\n      <td>Fieldnotes Epps/Obert; 2018</td>\n      <td>2019-01-14T03:46:55Z</td>\n      <td></td>\n      <td>wao taah</td>\n      <td>phrase</td>\n      <td>None</td>\n      <td>None</td>\n      <td>waʔoʔ ta:h</td>\n      <td>['802366cc-fff6-4c35-bff4-a403f4b4130d']</td>\n      <td>None</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>janooh_022d930d-b619-4a77-8ff4-fa5ea30739e8</td>\n      <td>Fieldnotes Epps/Obert; 2018</td>\n      <td>2018-07-07T20:57:29Z</td>\n      <td></td>\n      <td>janooh</td>\n      <td>stem</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>jaˈno:h</td>\n      <td>['9e409799-d500-44e1-97b4-66925497edde']</td>\n      <td>None</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>p’aa hẽnh_022f0eb2-2301-40e8-809c-927ccebeff3c</td>\n      <td>Fieldnotes Epps/Obert; 2018</td>\n      <td>2018-07-15T20:18:56Z</td>\n      <td></td>\n      <td>p’aa hẽnh</td>\n      <td>phrase</td>\n      <td>None</td>\n      <td>{'Sil Dict 2011': 'pʹaa hẽnh'}</td>\n      <td>paʔaʔ hẽɲ</td>\n      <td>['3954f8c6-283b-4e9f-a9b1-5e9ea6096fcc']</td>\n      <td>{'pʹaa hẽnh_988a43b7-7d72-4d87-be1d-c63c761e1d...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dajëp_024eb574-aa9a-4bea-adc6-12857406c334</td>\n      <td>Fieldnotes Epps/Obert; 2018</td>\n      <td>2018-07-10T00:09:23Z</td>\n      <td></td>\n      <td>dajëp</td>\n      <td>stem</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>daˈjǝp˺</td>\n      <td>['a8675526-039d-459c-b4c8-c3434645200d']</td>\n      <td>None</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tawarẽẽh1_025c1d2a-ce6b-4f4a-89c6-58f7995ce55a</td>\n      <td>Fieldnotes Epps/Obert; 2018</td>\n      <td>2018-03-08T07:17:53Z</td>\n      <td></td>\n      <td>tawarẽẽh</td>\n      <td>stem</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>tawaˈɾẽ:ʔ</td>\n      <td>['edf56ebd-dec5-40c2-8444-09892cd2d358']</td>\n      <td>None</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                         entry_id  \\\n0   wao taah_002ca005-1366-4a7b-aff1-ac10db10b768   \n1     janooh_022d930d-b619-4a77-8ff4-fa5ea30739e8   \n2  p’aa hẽnh_022f0eb2-2301-40e8-809c-927ccebeff3c   \n3      dajëp_024eb574-aa9a-4bea-adc6-12857406c334   \n4  tawarẽẽh1_025c1d2a-ce6b-4f4a-89c6-58f7995ce55a   \n\n                  bibliography                  date date_modified   headword  \\\n0  Fieldnotes Epps/Obert; 2018  2019-01-14T03:46:55Z                 wao taah   \n1  Fieldnotes Epps/Obert; 2018  2018-07-07T20:57:29Z                   janooh   \n2  Fieldnotes Epps/Obert; 2018  2018-07-15T20:18:56Z                p’aa hẽnh   \n3  Fieldnotes Epps/Obert; 2018  2018-07-10T00:09:23Z                    dajëp   \n4  Fieldnotes Epps/Obert; 2018  2018-03-08T07:17:53Z                 tawarẽẽh   \n\n  morph_type  note                   other_sources pronunciation  \\\n0     phrase  None                            None    waʔoʔ ta:h   \n1       stem    {}                            None       jaˈno:h   \n2     phrase  None  {'Sil Dict 2011': 'pʹaa hẽnh'}     paʔaʔ hẽɲ   \n3       stem    {}                            None       daˈjǝp˺   \n4       stem    {}                            None     tawaˈɾẽ:ʔ   \n\n                                      sense  \\\n0  ['802366cc-fff6-4c35-bff4-a403f4b4130d']   \n1  ['9e409799-d500-44e1-97b4-66925497edde']   \n2  ['3954f8c6-283b-4e9f-a9b1-5e9ea6096fcc']   \n3  ['a8675526-039d-459c-b4c8-c3434645200d']   \n4  ['edf56ebd-dec5-40c2-8444-09892cd2d358']   \n\n                                          these_vars variant_of  \n0                                               None         {}  \n1                                               None         {}  \n2  {'pʹaa hẽnh_988a43b7-7d72-4d87-be1d-c63c761e1d...         {}  \n3                                               None         {}  \n4                                               None         {}  "
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# header\n",
    "import pandas as pd\n",
    "import csv\n",
    "import AddIPAFlex\n",
    "import json\n",
    "import MatchHeadwords\n",
    "from GenerateLexDir import literal_eval_col\n",
    "from IPython.display import display\n",
    "from uuid import uuid4\n",
    "\n",
    "# load in df's\n",
    "flexicon = pd.read_csv('flexicon_NODUPLS.csv', keep_default_na=False)\n",
    "senses = pd.read_csv('SensesMERGE.csv', index_col='sense_id', keep_default_na=False)\n",
    "\n",
    "# take things literally\n",
    "#literal_eval_col(flexicon, 'sense')\n",
    "literal_eval_col(flexicon, 'note')\n",
    "literal_eval_col(flexicon, 'other_sources')\n",
    "literal_eval_col(flexicon, 'these_vars')\n",
    "literal_eval_col(flexicon, 'variant_of')\n",
    "\n",
    "literal_eval_col(senses, 'gloss')\n",
    "literal_eval_col(senses, 'def')\n",
    "flexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce consistent formatting in bibliography column\n",
    "#bib_bois = set(x for x in flexicon['bibliography'])\n",
    "#bib_bois\n",
    "new_bibs = []\n",
    "for bib in flexicon['bibliography']:\n",
    "    if not bib:\n",
    "        new_bibs.append(None)\n",
    "        continue\n",
    "    bib = bib.lower()\n",
    "    bib_str = ''\n",
    "    if 'epps' in bib:\n",
    "        bib_str = 'Fieldnotes Epps/Obert'\n",
    "        if '2018' in bib:\n",
    "            bib_str += ' 2018'\n",
    "        elif '2019' in bib:\n",
    "            bib_str += ' 2019'\n",
    "    elif 'martins' in bib:\n",
    "        bib_str = 'Martins 2005'\n",
    "    elif 'barbosa' in bib:\n",
    "        bib_str = 'Barbosa 2005'\n",
    "    elif 'weir' in bib:\n",
    "        bib_str = 'Weir'\n",
    "        if '1986' in bib:\n",
    "            bib_str += ' 1986,'\n",
    "        if '1990' in bib:\n",
    "            bib_str += ' 1990,'\n",
    "        if '1994' in bib:\n",
    "            bib_str += ' 1994'\n",
    "        elif bib_str.endswith(','):\n",
    "            bib_str = bib_str[:-1]\n",
    "    elif 'sil' in bib:\n",
    "        bib_str = 'SIL 2011'\n",
    "    else:\n",
    "        assert False, bib\n",
    "    new_bibs.append(bib_str)\n",
    "\n",
    "flexicon.loc[:,'bibliograghy'] = new_bibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0                                                    None\n1                                                      {}\n2                                                    None\n3                                                      {}\n4                                                      {}\n                              ...                        \n1114    {'Note': 'Predicted phonemic form from source ...\n1115                                                   {}\n1116                                                   {}\n1117                                                   {}\n1118                                                   {}\nName: note, Length: 1119, dtype: object"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also, remove bibliography key from notes column wherever present\n",
    "for n, b in zip(flexicon['note'],flexicon['bibliography']):\n",
    "    if n and 'bibliography' in n:\n",
    "        n.pop('bibliography')\n",
    "\n",
    "flexicon['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepend * to hypothetical forms\n",
    "for index, row in flexicon.iterrows():\n",
    "    note = row['note']\n",
    "    if note and 'Note' in note and note['Note'].startswith('Predicted phonemic'):\n",
    "        if 'Epps' in row['bibliography']:\n",
    "            note.pop('Note')\n",
    "        else:\n",
    "            hdwd = flexicon.at[index, 'headword']\n",
    "            hdwd = '*'+hdwd\n",
    "            flexicon.at[index, 'headword'] = hdwd\n",
    "            #display(flexicon.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "sense_id\ne92169c5-ce3e-4a09-9da4-f6860afd0478        Noun\n802366cc-fff6-4c35-bff4-a403f4b4130d        Noun\na0d825d5-a0ae-402d-8201-6805e39cad0b        Noun\n2e7ced09-86a7-4ad6-a7a0-e36f9523d65a        Noun\n062365d9-1fcd-4828-980d-5fbacad0019b        Noun\n                                          ...   \n92a34bd9-4de3-49ff-83f0-1371c7533ac8        adv?\n6c538c3e-c9e2-4c56-856c-455bef81dc6d        Noun\nb72bc68e-c154-487d-9fee-2457f25cba60      Adverb\n10d81977-d2bf-4e0b-a65f-4b3bcbecb92e        Noun\n5e84c851-3898-4013-a050-c8bff6e1c368    Particle\nName: pos, Length: 1636, dtype: object"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize PoS tags\n",
    "pos = set( s for s in  senses['pos'] )\n",
    "for index, pos in zip(senses.index, senses['pos']):\n",
    "    if '?' in pos:\n",
    "        continue\n",
    "    elif pos.startswith('v'):\n",
    "        senses.at[index, 'pos'] = 'Verb'\n",
    "    elif pos.startswith('n'):\n",
    "        senses.at[index, 'pos'] = 'Noun'\n",
    "    elif pos.startswith('adj'):\n",
    "        senses.at[index, 'pos'] = 'Adjective'\n",
    "    elif pos.startswith('con'):\n",
    "        senses.at[index, 'pos'] = 'Conjunction'\n",
    "    elif pos.startswith('int'):\n",
    "        senses.at[index, 'pos'] = 'Interjection'\n",
    "    elif pos.startswith('adv'):\n",
    "        senses.at[index, 'pos'] = 'Adverb'\n",
    "    elif pos.startswith('pos'):\n",
    "        senses.at[index, 'pos'] = 'Postposition'\n",
    "    elif pos.startswith('onom'):\n",
    "        senses.at[index, 'pos'] = 'Onomoatopoeia'\n",
    "    elif pos.startswith('pre'):\n",
    "        senses.at[index, 'pos'] = 'Prefix'\n",
    "    elif pos.startswith('suf'):\n",
    "        senses.at[index, 'pos'] = 'Suffix'\n",
    "    elif pos.startswith('par'):\n",
    "        senses.at[index, 'pos'] = 'Particle'\n",
    "    else:\n",
    "        pass#print(pos)\n",
    "senses['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{' ',\n '%',\n \"'\",\n '(',\n ')',\n '*',\n '-',\n '.',\n '/',\n ':',\n '=',\n '?',\n '́',\n '̃',\n '̰',\n '’'}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enforce consistent usage of apostrophes\n",
    "# start by finding all unique non-alphabetic chars in headwords\n",
    "nonalpha = set()\n",
    "for hdwd in flexicon['headword']:\n",
    "    for char in hdwd:\n",
    "        if not char.isalpha():\n",
    "            nonalpha.add(char)\n",
    "nonalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalpha = list(nonalpha)\n",
    "with open('punct.json', 'w') as f:\n",
    "    json.dump(nonalpha, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0             wao taah\n1               janooh\n2            p’aa hẽnh\n3                dajëp\n4             tawarẽẽh\n             ...      \n1114       *tḭ̃: hẽɲ\n1115             tĩĩnh\n1116    seeb %OR% seeh\n1117    wëëm %OR% wëm \n1118              eỹỹm\nName: headword, Length: 1119, dtype: object"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# literally only two unique apostrophes, don't need to load a json file for that\n",
    "for index in flexicon.index:\n",
    "    hdwd = flexicon.at[index, 'headword']\n",
    "    if \"'\" in hdwd:\n",
    "        flexicon.at[index, 'headword'] = hdwd.replace(\"'\", '\\u2019')\n",
    "flexicon['headword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "hooj1\nyb1\n =kóm1\n*hẽ1\n*na1\n*ʃa:h1\n*ko:k1\n*cɨ:1\n*do:1\n*pɔ̰̃:d1\n*do:2\n*ma1\n*puh1\n*na2\n"
    }
   ],
   "source": [
    "# update guids to reflect headwords\n",
    "headwords = list(flexicon['headword'])\n",
    "guids = [id.split(sep='_')[1] if id else None for id in flexicon['entry_id']]\n",
    "for i, hdwd in enumerate(headwords):\n",
    "    ct = headwords[:i].count(hdwd)\n",
    "    if ct:\n",
    "        hdwd+=str(ct)\n",
    "        print(hdwd)\n",
    "    guid = guids[i]\n",
    "    if not guid:\n",
    "        guid = str(uuid4())\n",
    "        assert guid not in guids\n",
    "    guids[i] = hdwd+'_'+guid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexicon.loc[:,'entry_id'] = guids\n",
    "flexicon = flexicon.set_index('entry_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexicon.to_csv('flexicon_3_3-FORMATTED.csv')\n",
    "senses.to_csv('senses_3_3-FORMATTED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}