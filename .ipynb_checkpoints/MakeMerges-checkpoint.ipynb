{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header\n",
    "import pandas as pd\n",
    "from GenerateLexDir import literal_eval_col\n",
    "from FindBib import read_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "flexicon = pd.read_csv('FlexiconMERGE.csv', index_col='entry_id', keep_default_na=False)\n",
    "merges = pd.read_csv('merge_matches.csv', index_col='entry_id', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take things literally\n",
    "literal_eval_col(flexicon, 'note')\n",
    "literal_eval_col(flexicon, 'other_sources')\n",
    "literal_eval_col(flexicon, 'sense')\n",
    "literal_eval_col(flexicon, 'these_vars')\n",
    "literal_eval_col(flexicon, 'variant_of')\n",
    "\n",
    "literal_eval_col(merges, 'matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to merges to reflect exit status on entry pairs that couldn't be merge\n",
    "merges.loc[:,'merge_error'] = ['']*len(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a backup of flexicon\n",
    "backup = flexicon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bib(bib):\n",
    "    bib = bib.lower()\n",
    "    if \"weir\" in bib:\n",
    "        return \"Weir\"\n",
    "    \n",
    "    elif \"martins\" in bib:\n",
    "        return \"Martins\"\n",
    "    \n",
    "    elif \"barbosa\" in bib:\n",
    "        return \"Barbosa\"\n",
    "    \n",
    "    elif \"epps\" in bib:\n",
    "        if '18' in bib:\n",
    "            return \"Epps/Obert Fieldnotes 2018\"\n",
    "        elif '19' in bib:\n",
    "            return \"Epps/Obert Fieldnotes 2019\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    elif \"sil\" in bib:\n",
    "        return \"Sil Dict\"\n",
    "    \n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write method to compare entries and merge data automatically\n",
    "# returns False to indicate that the entries could not be merged\n",
    "def merge_entries(id1, id2):\n",
    "    entry1 = flexicon.loc[id1]\n",
    "    entry2 = flexicon.loc[id2]\n",
    "    \n",
    "    new_entry = dict()\n",
    "    new_entry['other_sources'] = {}\n",
    "    \n",
    "    # bibliography & headword\n",
    "    # probz most complicated\n",
    "    bib1 = get_bib(entry1['bibliography'])\n",
    "    bib2 = get_bib(entry2['bibliography'])\n",
    "    \n",
    "    if bib1 == bib2:\n",
    "        new_entry['bibliography'] = bib1\n",
    "        hdwd1 = entry1['headword'].strip()\n",
    "        hdwd2 = entry2['headword'].strip()\n",
    "        if hdwd1 == hdwd2:\n",
    "            new_entry['headword'] = hdwd1\n",
    "        else:    \n",
    "            new_entry['headword'] = hdwd1 + ' %OR% ' + hdwd2\n",
    "    elif 'Epps' in bib1:\n",
    "        new_entry['bibliography'] = bib1\n",
    "        new_entry['other_sources'][bib2] = entry2['headword']\n",
    "        new_entry['headword'] = entry1['headword']\n",
    "    elif 'Epps' in bib2:\n",
    "        new_entry['bibliography'] = bib2\n",
    "        new_entry['other_sources'][bib1] = entry1['headword']\n",
    "        new_entry['headword'] = entry2['headword']\n",
    "    else:\n",
    "        return (False, 'Neither entry is from fieldnotes.')\n",
    "    \n",
    "    # date\n",
    "    # prefer newer one\n",
    "    date1 = entry1['date']\n",
    "    date2 = entry2['date']\n",
    "    new_entry['date'] = max(date1, date2)\n",
    "    \n",
    "    if entry1['date_modified']:\n",
    "        new_entry['date_modified'] = entry1['date_modified']\n",
    "    elif entry2['date_modified']:\n",
    "        new_entry['date_modified'] = entry2['date_modified']\n",
    "    else:\n",
    "        new_entry['date_modified'] = new_entry['date']\n",
    "        \n",
    "    # motph_type\n",
    "    # doesn't matter either\n",
    "    new_entry['morph_type'] = entry1['morph_type']\n",
    "    \n",
    "    # note\n",
    "    # try to merge keys into single dict\n",
    "    # return False if have overlapping keys\n",
    "    new_note = entry1['note'] if entry1['note'] else {}\n",
    "    note2 = entry2['note'] if entry2['note'] else {}\n",
    "    \n",
    "    for k, v in note2.items():\n",
    "        if k not in new_note:\n",
    "            new_note[k] = v\n",
    "        elif 'Predicted phonemic' in new_note[k]:\n",
    "            new_note[k] = v\n",
    "        elif 'Predicted phonemic' in v:\n",
    "            pass\n",
    "        elif new_note[k] == v:\n",
    "            pass\n",
    "        else:\n",
    "            return (False, 'Note field has conflicting data.')\n",
    "    new_entry['note'] = new_note\n",
    "        \n",
    "    # other_sources\n",
    "    # ditto\n",
    "    new_srcs = entry1['other_sources'] if entry1['other_sources'] else {}\n",
    "    srcs2 = entry2['other_sources'] if entry2['other_sources'] else {}\n",
    "    \n",
    "    for k, v in srcs2.items():\n",
    "        if k not in new_srcs:\n",
    "            new_srcs[k] = v\n",
    "        elif new_srcs[k] == v:\n",
    "            pass\n",
    "        else:\n",
    "            return (False, 'other_sources field has conflicting data.')\n",
    "    new_entry['other_sources'] = new_srcs\n",
    "        \n",
    "    # these_vars\n",
    "    # same spiel\n",
    "    new_vars = entry1['these_vars'] if entry1['these_vars'] else {}\n",
    "    vars2 = entry2['these_vars'] if entry2['these_vars'] else {}\n",
    "    \n",
    "    for k, v in vars2.items():\n",
    "        if k not in new_vars:\n",
    "            new_vars[k] = v\n",
    "        elif new_vars[k] == v:\n",
    "            pass\n",
    "        else:\n",
    "            return (False, 'these_vars field has conflicting data.')\n",
    "    new_entry['these_vars'] = new_vars\n",
    "    \n",
    "    # variant_of\n",
    "    # keep on keepin' on\n",
    "    new_varf = entry1['variant_of'] if entry1['variant_of'] else {}\n",
    "    varf2 = entry2['variant_of'] if entry2['variant_of'] else {}\n",
    "    \n",
    "    for k, v in varf2.items():\n",
    "        if k not in new_note:\n",
    "            new_varf[k] = v\n",
    "        elif new_varf[k] == v:\n",
    "            pass\n",
    "        else:\n",
    "            return (False, 'variant_of field has conflicting data.')\n",
    "        \n",
    "    # sense\n",
    "    # union of both lists\n",
    "    new_entry['sense'] = entry1['sense']+entry2['sense']\n",
    "    \n",
    "    # pronunciation\n",
    "    # preserve both if need be\n",
    "    # I plan on cleaning pronunciation later\n",
    "    pronc1 = entry1['pronunciation']\n",
    "    pronc2 = entry2['pronunciation']\n",
    "    if pronc1 and pronc2:\n",
    "        new_entry['pronunciation'] = pronc1 + ' %OR% ' + pronc2\n",
    "    elif pronc1:\n",
    "        new_entry['pronunciation'] = pronc1\n",
    "    elif pronc2:\n",
    "        new_entry['pronunciation'] = pronc2\n",
    "    else:\n",
    "        new_entry['pronunciation'] = ''\n",
    "        \n",
    "    return new_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf6106b490bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2c74e947e11b>\u001b[0m in \u001b[0;36mmerge_entries\u001b[0;34m(id1, id2)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# bibliography & headword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# probz most complicated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbib1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bibliography'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mbib2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bibliography'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0ab8530cb410>\u001b[0m in \u001b[0;36mget_bib\u001b[0;34m(bib)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_bib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"weir\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Weir\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# use merge_entries function to merge entries\n",
    "# (i'm sorry if you expected something else)\n",
    "\n",
    "# start by making df w/ all merges that can be merged w/o extra steps\n",
    "# (indicated by a note in the status col)\n",
    "merges_to_merge = [x=='merge' for x in merges['status']]\n",
    "merges_to_merge = merges[merges_to_merge]\n",
    "\n",
    "for index, row in merges_to_merge.iterrows():\n",
    "    result = None\n",
    "    for id2 in row['matches'].keys():\n",
    "        result = merge_entries(index, id2)\n",
    "        if type(result) is tuple:\n",
    "            break\n",
    "        else:\n",
    "            entry1 = result\n",
    "    # take advantage of python's weird for-else syntax\n",
    "    else:\n",
    "        # success case\n",
    "        flexicon.loc[index] = entry1\n",
    "        for id in row['matches'].keys():\n",
    "            flexicon = flexicon.drop(id)\n",
    "        merges = merges.drop(index)\n",
    "        continue\n",
    "    # failure case\n",
    "    merges.at[index, 'merge_error'] = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merges[merges['merge_error'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backup.shape)\n",
    "print(flexicon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup.to_csv('FlexiconMERGE-OLD.csv')\n",
    "flexicon.to_csv('FlexiconMERGE.csv')\n",
    "merges.to_csv('merge_matchesREMAINING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
